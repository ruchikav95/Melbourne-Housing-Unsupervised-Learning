# -*- coding: utf-8 -*-
"""Melbourne Housing Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YkET6x9Zp5m43kmZrmiWenzFH3oRTl3K
"""

#imports
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from plotly.subplots import make_subplots

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn import metrics 

import scikitplot as skplt

# color maps
from matplotlib import cm

# for distance and h-clustering
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from scipy.spatial.distance import pdist, squareform


# sklearn does have some functionality too, but mostly a wrapper to scipy
from sklearn.metrics import pairwise_distances 
from sklearn.preprocessing import StandardScaler

! pip install scikit-plot

"""# Loading Data"""

from google.colab import drive
drive.mount('/content/drive')

path = "/content/melb_data.csv"
df = pd.read_csv(path)

df.head(5)

df.shape

"""# Data Cleaning"""

#data types of each feature 
df.dtypes

# checking for null values
df.isnull().sum()

# converting the date column to 'datetime'
# the dataset consists of housing sales between 2016-2017
df['Date'] = pd.to_datetime(df['Date'])

#creating columns for the date and month the apartment was sold 
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month

import calendar
df['Month'] = df['Month'].apply(lambda x: calendar.month_abbr[x])

#real estate count per year and month
df.groupby(['Year', 'Month'])['Year'].count()

#dropping columns of no significance
df.drop(columns=['YearBuilt', 'Postcode', 'Address'], inplace=True)

#filling null values for council area with 'unavailable'
df['CouncilArea'] = df.CouncilArea.fillna('Unavailable')

#dropping observations with null values for car
df.dropna(subset=['Car'], inplace=True)

df.groupby(['BuildingArea', 'Suburb'])['Suburb'].count()

